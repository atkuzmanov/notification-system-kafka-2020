spring.application.name=@project.name@

logging.level.=INFO
logging.level.customLogbackLevel=INFO

spring.jpa.hibernate.ddl-auto=update
spring.datasource.url=jdbc:mysql://${MYSQL_HOST:localhost}:3306/db_example
spring.datasource.username=springuser
spring.datasource.password=ThePassword

supported.channel.list=email,sms,slack

spring.config.import=kafka.yml

#example.kafka.consumer-enabled=${consumer-enabled:true}
#spring.kafka.bootstrap-servers=${kafka_bootstrap_servers:localhost:9092}
#spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=${kafka_username:'admin'} password=${kafka_password:'admin-secret'};
#spring.kafka.properties.sasl.mechanism=PLAIN
#spring.kafka.properties.security.protocol=SASL_PLAINTEXT
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.group-id=example
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.max-poll-records=1
#spring.kafka.consumer.fetch-max-wait=36000
#spring.kafka.consumer.enable-auto-commit=false
#spring.kafka.consumer.client-id=example
#spring.kafka.producer.client-id=example
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.retries=2
#spring.kafka.jaas.enabled=true
#spring.kafka.listener.poll-timeout=1800000
#spring.kafka.listener.concurrency=1
#spring.kafka.listener.ack-mode=manual_immediate

